{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3692db2d",
   "metadata": {},
   "source": [
    "### Push dataset to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import os \n",
    "\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "api.upload_folder(\n",
    "    folder_path=\"data/rheo_sigmoid\",\n",
    "    repo_id=\"dchip95/synthetic-oscillatory-rheology-vlm\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92779eb6",
   "metadata": {},
   "source": [
    "##### check GPU VRAM and clear if in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42066cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418 MB currently allocated\n",
      "2466 MB currently reserved\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "if torch.cuda.is_available() and (torch.cuda.memory_allocated() // 1024 // 1024) > 10: \n",
    "    print(f\"{torch.cuda.memory_allocated() // 1024 // 1024} MB currently allocated\")\n",
    "    print(f\"{torch.cuda.memory_reserved() // 1024 // 1024} MB currently reserved\")\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a608c",
   "metadata": {},
   "source": [
    "#### Import libraries and set torch device properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4312411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig, AutoModelForCausalLM, AutoProcessor\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# model_id = \"OpenGVLab/InternVL3-2B\"\n",
    "model_id = 'microsoft/Florence-2-base-ft'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# florence 2 \n",
    "# load processor \n",
    "# inputs loaded into processor \n",
    "# processor processed inputs to go to model\n",
    "# model object calls generate()\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True,)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                quantization_config=bnb_config,\n",
    "                                low_cpu_mem_usage=True, \n",
    "                                trust_remote_code=True).eval()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ea733",
   "metadata": {},
   "source": [
    "#### From https://huggingface.co/blog/finetune-florence2 they freeze the vision encoder to make fine tuning less expensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb25a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.vision_tower.parameters(): \n",
    "    param.is_trainable = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef94263",
   "metadata": {},
   "source": [
    "#### Now we can begin the finetune process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe85ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
